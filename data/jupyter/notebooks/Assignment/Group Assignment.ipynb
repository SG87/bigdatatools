{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png\" width=\"200\" height=\"200\" />\n",
    "<p></p>\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "<img src=\"https://www.vectorlogo.zone/logos/apache_kafka/apache_kafka-ar21.svg\" width=\"200\" height=\"200\" /> \n",
    "\n",
    "<img src=\"https://www.teaminformatics.com/wp-content/uploads/2017/05/elasticsearch-logo-1200x625.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "<img src=\"https://oliverveits.files.wordpress.com/2016/11/kibana-logo-color-v.png\" width=\"200\" height=\"200\" />\n",
    "</center>\n",
    "\n",
    "\n",
    "# Group Assignment Big Data Tools 2\n",
    "\n",
    "In this assignment you are going to build on the results of the individual assignment and give the Belgian second hand car dealer some more advice.\n",
    "\n",
    "The car dealer has decided he wants to focus his activities on **German cars** (Audi, BMW, Mercedes, Opel, Porsche, and Volkswagen (VW)). He has heard rumours that it is possible analyze _tweets_ of cars with **streaming technology** so he asks you to do this for him. Additionally he wants to build a website with a **search engine**. He asks you to demo some searching capabilities with **ElasticSearch**.\n",
    "\n",
    "Can you help the Belgian car dealer by answering his questions?\n",
    "\n",
    "\n",
    "<center><img src=\"https://www.ocbc.com/assets/images/uploads/loans/inside_carloan/autofinancing_used_car.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Grading percentage: 40%\n",
    "\n",
    "Due Date: 20/12/2017\n",
    "\n",
    "Send assignment to: s.geuens@ieseg.fr\n",
    "\n",
    "Accepted formats: Zeppelin notebook (.json)\n",
    "\n",
    "If you have finished the assignment, save this notebook pressing the \"Export this note\" icon on top in the middle of this page. The notebook will be saved as a .json file on your local machine. Rename this file as **lastname1_firstname1_&_lastname2_firstname2_&_....json**. and send it to s.geuens@ieseg.fr.\n",
    "\n",
    "You can include the ElasticSearch code into the Zeppelin notebook using the **%elasticsearch** tag. It is not necessary to develop the code in the notebook. You can write your code in Kibana and afterwards copy it into the Zeppelin notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The assignment\n",
    "\n",
    "**The assignment consists of four major parts:**\n",
    "- Part 1: Putting the base file into HDFS\n",
    "- Part 2: Reading the file in Spark from HDFS\n",
    "- Part 3: Doing transformations and basic actions in Spark\n",
    "- Part 4: Calculating ML models in Spark\n",
    "- Part 5: Theoretical questions\n",
    "\n",
    "This notebook is divided into these five parts. At the start of each part, an explanation of the expectations is given.\n",
    "\n",
    "The assignment is grades based on logic and effort, not on final results. If you make mistakes try to complete the steps that follow, even if you cannot complete them correctly anymore. Showing your understanding of what you need to do, is as important as the final results. At the end of each block a test paragraph is included. This test paragraph already gives you an indication whether your answer is right or wrong.\n",
    "\n",
    "> As mentioned, grades are not only give based on final results. Try to be as complete as possible and make notes using and adding comments (#) or %md cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Loading Modules\n",
    "\n",
    "In this part the modules used in Part 1-3 are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Streaming\n",
    "\n",
    "Your first task is to create a Kafka producer that collect all tweet about the German car brands (Audi, BMW, Mercedes, Opel, Porsche, and Volkswagen (VW)). Collect these tweets in a Kafka topic called \"cars\".\n",
    "\n",
    "> Note: As you cannot do this task in Zeppelin, describe the steps you took together with the commands your ran in the %md cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Spark Streaming\n",
    "In class you have seen how to consume a Kafka topic using Spark Streaming and add a sentiment to the tweets. In this part, we are going to do exactly the same. Of course some additional transformations are wanted.\n",
    "\n",
    "* 2a) Define general RDD helper functions\n",
    "* 2b) Sentiment analysis: Create helper lists and define 7 sentiment analysis functions\n",
    "* 2c) Brand function\n",
    "* 2d) Combine all helper functions in DFActions function\n",
    "* 2e) Specifying arguments and parameters\n",
    "* 2f) Initialize the StreamingContext (ssc)\n",
    "* 2g) Initializing of the stream and creation of the execution plan\n",
    "* 2h) Start the stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Define general RDD helper functions\n",
    "\n",
    "The `selectFields()` and `makeSchema()` function need to be defined. These functions will help to transform the RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define selectFields()\n",
    "<FILL IN>\n",
    "\n",
    "# define makeSchema\n",
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Sentiment analysis: Create helper lists and define 7 sentiment analysis functions\n",
    "\n",
    "As done in class, the same **postive** and **negative** helper list need to be created to use later in application.\n",
    "\n",
    "In class we saw how to define a general `sentimentAnalysis()` function. Here we are going to repeat this sentiment analysis function, but are ging to create 6 additional sentimentAnalysis functions. One for for each car brand. The functions return the semintiment towards the brand if the brand name is included in the text of the tweet, otherwise None. This will create for example a function called `SentimentAnalysisAudi()`. Make sure to transform them to UDF, so you can use them on dataframes in the streaming context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create helper lists\n",
    "positive = <FILL IN>\n",
    "negative <FILL IN>\n",
    "\n",
    "print(len(positive))\n",
    "print(len(negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create SentimentAnalysis Function\n",
    "<FILL IN>\n",
    "\n",
    "# Create SentimentAnalysis Function for Audi\n",
    "<FILL IN>\n",
    "\n",
    "# Create SentimentAnalysis Function for BMW\n",
    "<FILL IN>\n",
    "\n",
    "# Create SentimentAnalysis Function for Mercedes\n",
    "<FILL IN>\n",
    "\n",
    "# Create SentimentAnalysis Function for Opel\n",
    "<FILL IN>\n",
    "\n",
    "# Create SentimentAnalysis Function Porsche\n",
    "<FILL IN>\n",
    "\n",
    "# Create SentimentAnalysis Function Volkswagen / VW\n",
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) Brand function\n",
    "\n",
    "A final helper function is the `brand()`function. This function extracts the brand from text and creates a column **brand** containing the name of the brand in lower case string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brand(text):\n",
    "    <FILL IN>\n",
    "\n",
    "udfBrand = <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d) Combine all helper functions in DFActions function\n",
    "\n",
    "As done in class, a `DFActions()`should be defined that transforms the RDD to DF and executes all functions defined in 2b and 2c.\n",
    "\n",
    "Additionally, you already need to prepare for part 3 and save the DF to be able to use it in ElasticSearch in the third part of this assignment. There are two options:\n",
    "1) Write the DF directly to **ElasticSearch**, more specific to /cars_twitter/default (/index/type).\n",
    "2) If your are not able to execute option 1, you can write the resulting DF  to a **local JSON file** with name: \"/home/bigdata/assignment/data/output/cars_twitter\".\n",
    "\n",
    "> Note: We want to collect all the tweets, so use the **append** mode. In this way new run will be append to the same JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DFActions(rdd):\n",
    "    # transform RDD to DF\n",
    "    DF =  <FILL IN>\n",
    "    \n",
    "    # apply functions in 2b and 2c\n",
    "    DfSentiment = <FILL IN>\n",
    "    \n",
    "    # Write resulting df to ElasticSearch or local JSON file\n",
    "    \n",
    "    <FILL IN>\n",
    "    \n",
    "    # Show the 5 first columns and print the number tweets read during the last run\n",
    "    <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e) Specifying arguments and parameters\n",
    "\n",
    "The helper functions take arguments as input. In the cell below, the **fields** argument for the **selectFields** and **makeSchema** function is defined. Additionally we define to which topic Spark should listen, the interval Spark Streaming should run and finally the location of Zookeeper.\n",
    "\n",
    "Here we want to retain the \"id\", \"created_at\", \"text\", \"user.location\", \"entities.hashtags\", \"entities.user_mentions\", \"lang\", and \"timestamp_ms\" fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fields = <FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zkQuorum = <FILL IN>\n",
    "topic = <FILL IN>\n",
    "\n",
    "seconds_to_run = <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2f) Initialize the StreamingContext (ssc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2g) Initializing of the stream and creation of the  execution plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialization of the Stream\n",
    "<FILL IN>\n",
    "\n",
    "# string to directory\n",
    "<FILL IN>\n",
    "\n",
    "# select the necessary fields\n",
    "<FILL IN>\n",
    "\n",
    "# define schema\n",
    "<FILL IN>\n",
    "\n",
    "# transform to DF and perform the DFActions\n",
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2h) Start the stream\n",
    "\n",
    "Let this stream run for about 20 minutes to collect enough tweets about the German cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: ElasticSearch\n",
    "\n",
    "In part 2 we have performed streaming sentiment analysis. The Belgian dealer is pleased to see the results. Nevertheless he wants to go a step further. He wants to create a search engines:\n",
    "1) A search engine on his website to search for cars\n",
    "2) An internal search engine in which he can search the tweets for German cars\n",
    "\n",
    "The car dealer wants to be convinced of the power of ElasticSearch and askes you to run 15 queries. Are you able to construct these queries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Indexes\n",
    "\n",
    "There are already two indexes (with types) available in ElasticSearch:\n",
    "* **/cars/cars_db**: An index/type containing the cars for sale on the Belgian market. This index is the result of the individual assignment.\n",
    "* **cars_twitter/tweets**: An index/type containing tweets about German cars. This index is the result of part 2 in this assignment.\n",
    "\n",
    "You first job is to look at the mappings. Can you answer the following questions:\n",
    "* What type is the field **age** in the /cars/cars_db index?\n",
    "* What type is the field **brandName** in the /cars/cars_db index?\n",
    "* What does the following key-value pair mean?\n",
    "            **\"fields\": { \"keyword\": { \"type\": \"keyword\"}}**\n",
    "* What does **\"ignore_above: 256\"** mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Searching\n",
    "\n",
    "In this part, you need to perform queries in ElasticSearch (Kibana). Each query needs to be pasted into the %elasticsearch cell. In the %md cell \"Hits\" the number of hits should be entered. Finally, if an additional qestion is asked, you should answer in the %md cell with \"Answer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (Example):\n",
    "Create a query that returns all the documents in the cars_twitter/tweets index.\n",
    "Was this easy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch\n",
    "GET /cars_twitter/tweets/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match_all\": {}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits\n",
    "6538"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Create a query that return all the **oldtimers** in the **cars/cars_db** index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "Find all the German cars in the cars/cars_bd index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "\n",
    "Return all the cars with a **price** between 20000 and 30000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5:\n",
    "\n",
    "Return the models of which the name only consist of numbers. (Hint: **regexp** query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6:\n",
    "Return the tweets that have a **brand** field that is not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7:\n",
    "\n",
    "Return the tweets that contain **Mercedes** (case insensitive) in their text body.\n",
    "\n",
    "How come the car with id \"AV-XehVbcAXvn561YE47\" is include in the results, while no brand field is present for this car?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8:\n",
    "\n",
    "Return the tweets that have **audi** (case insensitive) in their **hashtags** or **mentions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9:\n",
    "\n",
    "Create a query that returns the tweets with the exact phrase **\"sports car\"** (case insensitive) in their text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10:\n",
    "Return the tweets with **BMW** in their body that have a **positive sentiment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11:\n",
    "In ElasticSearch you can accomplish the same result with multiple queries. Can you create a query that returns the same results as question 10, while another query is executed?\n",
    "\n",
    "What is the difference in reasoning between the query you executed in question 10 and 11?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "Return tweets that contain **Audi** that do **not** have a **positive sentiment**. Give priority to tweets that contain **R8** without excluding other tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "Similarly to question 12, find tweets about **Audi**, tweeted from **Singapore**, and have **no negative sentiment**. Give priority to tweets that contain **R8** without excluding other tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "Create a query that returns the **young German cars** that do **not** have a **mileage higher or equal to 10000 km**. Give priority to powerful cars with an **engine power greater or equal to 150 kW** without excluding other results.\n",
    "Note that we want to use this result on the webpage. We only want to show **3 variabels: \"brandName\", \"modelName\", and \"sellingPrice\"**. Additionally we want to use pagination and show only the second page showing results **10 - 20**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "Finally you should run a query that returns the tweets having **english** as language and contain the phrase **Porche Boxster**. Note that the words \"Porsche\" and \"Boxster\" should be close to each other and **maximum 1 word** can be in between the two words. Additionally the tweets may **NOT** have a **negative sentiment**. For esthetic reasons, the searched terms (Porsche Boxster) should be **highlighted** in bold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ytimg.com/vi/P4LhWSN3YSw/maxresdefault.jpg\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
