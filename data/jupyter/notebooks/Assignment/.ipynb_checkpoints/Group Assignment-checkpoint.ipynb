{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png\" width=\"200\" height=\"200\" />\n",
    "<p></p>\n",
    "<img src=\"http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "<img src=\"https://www.vectorlogo.zone/logos/apache_kafka/apache_kafka-ar21.svg\" width=\"200\" height=\"200\" /> \n",
    "\n",
    "<img src=\"https://www.teaminformatics.com/wp-content/uploads/2017/05/elasticsearch-logo-1200x625.png\" width=\"200\" height=\"200\" />\n",
    "\n",
    "<img src=\"https://oliverveits.files.wordpress.com/2016/11/kibana-logo-color-v.png\" width=\"200\" height=\"200\" />\n",
    "</center>\n",
    "\n",
    "\n",
    "# Group Assignment Big Data Tools 2\n",
    "\n",
    "In this assignment you are going to build on the results of the individual assignment and give the Belgian second hand car dealer some more advice.\n",
    "\n",
    "The car dealer has decided he wants to focus his activities on **German cars** (Audi, BMW, Mercedes, Opel, Porsche, and Volkswagen (VW)). He has heard rumours that it is possible analyze _tweets_ of cars with **streaming technology** so he asks you to do this for him. Additionally he wants to build a website with a **search engine**. He asks you to demo some searching capabilities with **ElasticSearch**.\n",
    "\n",
    "Can you help the Belgian car dealer by answering his questions?\n",
    "\n",
    "\n",
    "<center><img src=\"https://www.ocbc.com/assets/images/uploads/loans/inside_carloan/autofinancing_used_car.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "Grading percentage: 40%\n",
    "\n",
    "Due Date: 20/12/2017\n",
    "\n",
    "Send assignment to: s.geuens@ieseg.fr\n",
    "\n",
    "Accepted formats: Jupyter notebook (.ipynb)\n",
    "\n",
    "If you have finished the assignment, save this notebook as a *ipynb* file. Rename this file as **lastname1_firstname1_&_lastname2_firstname2_&_....ipynb**. and send it to s.geuens@ieseg.fr.\n",
    "\n",
    "You can include the ElasticSearch code into the Jupyter notebook as Markdown.  You can write your code in Kibana and afterwards copy it into the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The assignment\n",
    "\n",
    "**The assignment consists of four major parts:**\n",
    "- Part 0: Loading Modules\n",
    "- Part 1: Streaming\n",
    "- Part 4: Calculating ML models in Spark\n",
    "- Part 5: Theoretical questions\n",
    "\n",
    "This notebook is divided into these three parts. At the start of each part, an explanation of the expectations is given.\n",
    "\n",
    "The assignment is grades based on logic and effort, not on final results. If you make mistakes try to complete the steps that follow, even if you cannot complete them correctly anymore. Showing your understanding of what you need to do, is as important as the final results. \n",
    "\n",
    "> As mentioned, grades are not only give based on final results. Try to be as complete as possible and make notes using and adding comments (#) or %md cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Loading Modules\n",
    "\n",
    "In this part the modules used in Part 1-3 are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from kafka import KafkaConsumer\n",
    "import pandas\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Kafka Producer\n",
    "\n",
    "Your first task is to create a Kafka producer that collect all tweet about the German car brands (Audi, BMW, Mercedes, Opel, Porsche, and Volkswagen (VW)). Collect these tweets in a Kafka topic called \"cars\".\n",
    "\n",
    "> Note: As you cannot do this task in Jupyter, describe the steps you took together with the commands your ran in the %md cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kafka commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Kafka Consumer\n",
    "In class you have seen how to consume a Kafka topic using Spark Streaming and add a language to the Tweets. In this part, we are going to do a real basic sentiment analysis on Tweets. \n",
    "\n",
    "* 2a) Create a Kafka consumer\n",
    "* 2b) Sentiment analysis: Create helper lists and define 7 sentiment analysis functions\n",
    "* 2c) Brand function\n",
    "* 2d) Combine all helper functions in DFActions function\n",
    "* 2e) Specifying arguments and parameters\n",
    "* 2f) Initialize the StreamingContext (ssc)\n",
    "* 2g) Initializing of the stream and creation of the execution plan\n",
    "* 2h) Start the stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Create a Kafka consumer\n",
    "\n",
    "Define a Kafka consumer that listens to the \"cars\" topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define consumer\n",
    "\n",
    "consumer = <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = consumer.poll()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Sentiment analysis: Create helper lists\n",
    "\n",
    "You can find two files: **positive-words.txt** and **negative-words.txt** in the **/data** directory. These files contain a list of positive words and negative words respectively. In the cell below you should read these files as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "4783\n"
     ]
    }
   ],
   "source": [
    "# Create helper lists\n",
    "positive = [line.rstrip('\\n') for line in open(\"/data/positive-words.txt\", errors='ignore')]\n",
    "print(len(positive))\n",
    "negative = <FILL IN>\n",
    "print(len(negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) Create functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three function will be created:\n",
    "    - sentiment: Adds a sentiment variable to each Tweet\n",
    "    - brand: Adds a brand variable to each Tweet\n",
    "    - sentimentAnalysis: Main function with:\n",
    "        - consume Kafka topic cars\n",
    "        - transform the input to list of dictionaries\n",
    "        - apply the sentiment function on each element of the Tweets list\n",
    "        - apply the brand function on each element of th Tweets list\n",
    "        - transform list of dictionaries to a Pandas dataframe\n",
    "        - Calculate count statistics on the Pandas dataframe grouped by sentiment and prints them\n",
    "        - Calculate count statistics on the Pandas dataframe grouped by brand and sentiment and returns them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment function:\n",
    "    - extracts the \"text\" field out of the tweet (= dictionary) and splits the text into a list of tokens.\n",
    "    - counts the number of positive and negative words by taking the intersection between the words in the text of the tweet and positive or negative word list\n",
    "    - create sentiment key:\n",
    "        - If the number of positive words is equal to the number of negative words -> neutral\n",
    "        - If the number of positive words is bigger than the number of negative words -> positive\n",
    "        - If the number of positive words is smaller than the number of negative words -> negative\n",
    "    - add the sentiment variable to the tweet dictionary\n",
    "    - return the enriched tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(tweet):\n",
    "    text = <FILL IN>\n",
    "    positive_count = len(set(text).intersection(set(positive)))\n",
    "    negative_count = <FILL IN>\n",
    "    if positive_count == negative_count:\n",
    "        sentiment = <FILL IN>\n",
    "    elif <FILL IN>:\n",
    "        <FILL IN>\n",
    "    else:\n",
    "        <FILL IN>\n",
    "    tweet[\"sentiment\"] = <FILL IN>\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brand function:\n",
    "    - Checks for every brand if it is in the tweet[\"text\"] field in a case unsensitive way. This is done by applying if, elif, else logic\n",
    "    - add the brand variable to the tweet dictionary\n",
    "    - return the enriched tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand(tweet):\n",
    "    if \"audi\" in tweet[\"text\"].lower():\n",
    "        <FILL IN>\n",
    "    elif <FILL IN>:\n",
    "        <FILL IN>\n",
    "    elif <FILL IN>:\n",
    "        <FILL IN>\n",
    "    elif <FILL IN>:\n",
    "        <FILL IN>\n",
    "    elif <FILL IN>:\n",
    "        <FILL IN>\n",
    "    elif <FILL IN>:\n",
    "        <FILL IN>\n",
    "    else:\n",
    "        brand = \"Other\"\n",
    "    tweet[\"brand\"] = <FILL IN>\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentimentAnalysis function:\n",
    "    - consume Kafka topic cars\n",
    "    - transform the input to list of dictionaries\n",
    "    - apply the sentiment function on each element of the Tweets list\n",
    "    - apply the brand function on each element of th Tweets list\n",
    "    - transform list of dictionaries to a Pandas dataframe\n",
    "    - Calculate count statistics on the Pandas dataframe grouped by sentiment and prints them\n",
    "    - Calculate count statistics on the Pandas dataframe grouped by brand and sentiment and returns them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SentimentAnalysis Function\n",
    "def sentimentAnalysis():\n",
    "    # consume Kafka topic cars\n",
    "    c = <FILL IN>\n",
    "    \n",
    "    try:\n",
    "        # transform the input to list of dictionaries\n",
    "        tweets = <FILL IN>\n",
    "        \n",
    "        # apply the sentiment function on each element of the Tweets list\n",
    "        tweets_sentiment = list(map(lambda tweet: <FILL IN>, tweets))\n",
    "        \n",
    "        # apply the brand function on each element of th Tweets list\n",
    "        tweets_sentiment_brand = list(map(lambda tweet: <FILL IN>, tweets_sentiment))\n",
    "        \n",
    "        # transform list of dictionaries to a Pandas dataframe\n",
    "        tweets_pd = <FILL IN>\n",
    "        \n",
    "        # Calculate count statistics on the Pandas dataframe grouped by sentiment and prints them\n",
    "        print(<FILL IN>)\n",
    "        \n",
    "        # Calculate count statistics on the Pandas dataframe grouped by brand and sentiment and returns them\n",
    "        tweets_pd_brand = <FILL IN>\n",
    "        return tweets_pd_brand\n",
    "    \n",
    "    except:\n",
    "        print(\"No tweets to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d) Create a loop to consume Tweets\n",
    "\n",
    "Create a loop that executes the sentimentAnalysis function every 4 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: ElasticSearch\n",
    "\n",
    "In part 2 we have performed streaming sentiment analysis. The Belgian dealer is pleased to see the results. Nevertheless he wants to go a step further. He wants to create a search engines:\n",
    "1) A search engine on his website to search for cars\n",
    "2) An internal search engine in which he can search the tweets for German cars\n",
    "\n",
    "The car dealer wants to be convinced of the power of ElasticSearch and askes you to run 15 queries. Are you able to construct these queries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Indexes\n",
    "\n",
    "There are already two indexes (with types) available in ElasticSearch:\n",
    "* **/cars/cars_db**: An index/type containing the cars for sale on the Belgian market. This index is the result of the individual assignment.\n",
    "* **cars_twitter/tweets**: An index/type containing tweets about German cars. This index is the result of part 2 in this assignment.\n",
    "\n",
    "You first job is to look at the mappings. Can you answer the following questions:\n",
    "* What type is the field **age** in the /cars/cars_db index?\n",
    "* What type is the field **brandName** in the /cars/cars_db index?\n",
    "* What does the following key-value pair mean?\n",
    "            **\"fields\": { \"keyword\": { \"type\": \"keyword\"}}**\n",
    "* What does **\"ignore_above: 256\"** mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Searching\n",
    "\n",
    "In this part, you need to perform queries in ElasticSearch (Kibana). Each query needs to be pasted into the %elasticsearch cell. In the %md cell \"Hits\" the number of hits should be entered. Finally, if an additional qestion is asked, you should answer in the %md cell with \"Answer\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (Example):\n",
    "Create a query that returns all the documents in the cars_twitter/tweets index.\n",
    "Was this easy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch\n",
    "GET /cars_twitter/tweets/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"match_all\": {}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits\n",
    "6538"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Create a query that return all the **oldtimers** in the **cars/cars_db** index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "Find all the German cars in the cars/cars_bd index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "\n",
    "Return all the cars with a **price** between 20000 and 30000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5:\n",
    "\n",
    "Return the models of which the name only consist of numbers. (Hint: **regexp** query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6:\n",
    "Return the tweets that have a **brand** field that is not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7:\n",
    "\n",
    "Return the tweets that contain **Mercedes** (case insensitive) in their text body.\n",
    "\n",
    "How come the car with id \"AV-XehVbcAXvn561YE47\" is include in the results, while no brand field is present for this car?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8:\n",
    "\n",
    "Return the tweets that have **audi** (case insensitive) in their **hashtags** or **mentions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9:\n",
    "\n",
    "Create a query that returns the tweets with the exact phrase **\"sports car\"** (case insensitive) in their text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10:\n",
    "Return the tweets with **BMW** in their body that have a **positive sentiment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11:\n",
    "In ElasticSearch you can accomplish the same result with multiple queries. Can you create a query that returns the same results as question 10, while another query is executed?\n",
    "\n",
    "What is the difference in reasoning between the query you executed in question 10 and 11?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "Return tweets that contain **Audi** that do **not** have a **positive sentiment**. Give priority to tweets that contain **R8** without excluding other tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "Similarly to question 12, find tweets about **Audi**, tweeted from **Singapore**, and have **no negative sentiment**. Give priority to tweets that contain **R8** without excluding other tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "Create a query that returns the **young German cars** that do **not** have a **mileage higher or equal to 10000 km**. Give priority to powerful cars with an **engine power greater or equal to 150 kW** without excluding other results.\n",
    "Note that we want to use this result on the webpage. We only want to show **3 variabels: \"brandName\", \"modelName\", and \"sellingPrice\"**. Additionally we want to use pagination and show only the second page showing results **10 - 20**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "Finally you should run a query that returns the tweets having **english** as language and contain the phrase **Porche Boxster**. Note that the words \"Porsche\" and \"Boxster\" should be close to each other and **maximum 1 word** can be in between the two words. Additionally the tweets may **NOT** have a **negative sentiment**. For esthetic reasons, the searched terms (Porsche Boxster) should be **highlighted** in bold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ytimg.com/vi/P4LhWSN3YSw/maxresdefault.jpg\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
